
configfile: "config/config.yaml"
HM3 = config["HM3"]
DATAOUT = config["DATAOUT"]
SAMPLE = config["SAMPLE"]
REFNAME = config["REFNAME"]
tgped = config["tgped"]
GenoMiss = config["GenoMiss"]
kb = config["kb"]
size = config["size"]
r2 = config["r2"]
SampMiss= config["SampMiss"]
MAF = config["MAF"]
HWE = config["HWE"]
BUILD = config["BUILD"]
BPLINK = [".bed", ".bim", ".fam"]

rule all:
    input:
        expand("{dataout}/plots/{sample}_{refname}_pca_tern.png",
                 dataout = DATAOUT, sample = SAMPLE,refname = REFNAME),
        expand("{dataout}/{sample}_{refname}_merged_assigned_ancestry.tsv",
                 dataout = DATAOUT, sample = SAMPLE,refname = REFNAME),
        expand("{dataout}/plots/{sample}_{refname}_admixture.png",
                dataout = DATAOUT, sample = SAMPLE,refname = REFNAME),
        expand("{dataout}/plots/{sample}_{refname}_admixture_assigned.png",
                dataout = DATAOUT, sample = SAMPLE,refname = REFNAME)

# Exclude SNPs with a high missing rate and low MAF
rule snp_qc:
    input:
        multiext("data/{sample}", ".bed", ".bim", ".fam")
    output:
        multiext("{dataout}/{sample}_SnpQc",".bed", ".bim", ".fam"),
        "{dataout}/{sample}_SnpQc.hwe",
        "{dataout}/{sample}_SnpQc.frq",
        "{dataout}/{sample}_SnpQc.frqx",
    params:
        indat = "data/{sample}",
        out = "{dataout}/{sample}_SnpQc",
        GenoMiss = GenoMiss,
        MAF = MAF,
        HWE = HWE
    conda: "envs/plink.yaml"
    shell:
        r'''
        plink --keep-allele-order --bfile {params.indat} --freq --out {params.out}
        plink --keep-allele-order --bfile {params.indat} --freqx --out {params.out}
        plink --keep-allele-order --bfile {params.indat} --geno {params.GenoMiss} \
        --maf {params.MAF} --hardy --hwe {params.HWE} --make-bed --out {params.out}
        '''

# Exclude Samples with high missing rate
rule sample_callRate:
    input: multiext("{dataout}/{sample}_SnpQc", ".bed", ".bim", ".fam")
    output: multiext("{dataout}/{sample}_callRate", ".bed", ".bim", ".fam"),
            "{dataout}/{sample}_callRate.imiss",
            touch("{dataout}/{sample}_callRate.irem")
    params:
        indat = "{dataout}/{sample}_SnpQc",
        SampMiss = SampMiss,
        out = "{dataout}/{sample}_callRate"
    conda: "envs/plink.yaml"
    shell:
        r'''
        plink --keep-allele-order --bfile {params.indat} --mind {params.SampMiss} \
        --missing --make-bed --out {params.out}
        '''
# Align sample to fasta reference
rule Sample_Flip:
    input:
        bim = rules.sample_callRate.params.out + '.bim',
        bed = rules.sample_callRate.params.out + '.bed',
        fam = rules.sample_callRate.params.out + '.fam',
        fasta = expand("data/reference/human_g1k_{gbuild}.fasta", gbuild=BUILD)
    output:
        multiext("{dataout}/{sample}_flipped", ".bim", ".bed", ".fam")
    params:
        dataout = DATAOUT
    container: 'docker://befh/flippyr:0.4.0'
    shell: "flippyr -p {input.fasta} -o {params.dataout}/{wildcards.sample} {input.bim}"

rule Sample_ChromPosRef:
    input:
        flipped = rules.Sample_Flip.output[0]
    output:
        bim = temp("{dataout}/{sample}_flipped_ChromPos.bim"),
        snplist = temp("{dataout}/{sample}_flipped_snplist")
    conda: "envs/r.yaml"
    script: "scripts/bim_ChromPosRefAlt.R"

# Prune sample dataset - input prune command
rule sample_hapmap:
    input:
        fileset = multiext("{dataout}/{sample}_flipped", ".bed", ".bim", ".fam"),
        prune = HM3,
        bim = rules.Sample_ChromPosRef.output.bim
    output:
        multiext("{dataout}/{sample}_hapmap", ".bed", ".bim", ".fam")
    params:
        indat = "{dataout}/{sample}_flipped",
        out = "{dataout}/{sample}_hapmap"
    conda: "envs/plink.yaml"
    shell:
        r"""
        plink --keep-allele-order --bfile {params.indat} --bim {input.bim} \
          --extract {input.prune} \
          --make-bed --out {params.out}
        """
# Thin sample dataset
rule thinning:
    input: rules.sample_hapmap.output
    output:
        multiext("{dataout}/{sample}_hapmap", ".prune.in", ".prune.out"),
        "{dataout}/{sample}_hapmap.dupvar"
    params:
        window = 50,
        size = size,
        r2 = r2,
        stem = rules.sample_hapmap.params.out,
        out = "{dataout}/{sample}_hapmap"
    conda: "envs/plink.yaml"
    shell:
        r"""
        plink --keep-allele-order --bfile {params.stem} --indep-pairwise {params.window} {params.size} {params.r2}\
        --list-duplicate-vars --out {params.out}
        """
#  Extract thinned sample dataset
rule extract_thin:
    input:
        rules.sample_hapmap.output,
        thin = rules.thinning.output[0],
        dupvars = rules.thinning.output[2]
    output: multiext("{dataout}/{sample}_thinned", ".bim", ".bed", ".fam")
    params:
        stem = rules.sample_hapmap.params.out,
        out = "{dataout}/{sample}_thinned"
    conda: "envs/plink.yaml"
    shell:
        r"""
        plink --keep-allele-order --bfile {params.stem} --extract {input.thin} \
        --exclude {input.dupvars} --make-bed --out {params.out}
        """
# Recode sample plink file to vcf
rule Sample_Plink2Bcf:
    input:
        rules.extract_thin.output
    output: "{dataout}/{sample}_thinned.vcf.gz"
    params:
        stem = rules.extract_thin.params.out,
        out = "{dataout}/{sample}_thinned"
    conda: "envs/plink.yaml"
    shell:
        r"""
        plink --bfile {params.stem} --recode vcf bgz \
          --real-ref-alleles --out {params.out}
        """

# Index bcf
rule Sample_IndexBcf:
    input: rules.Sample_Plink2Bcf.output
    output: "{dataout}/{sample}_thinned.vcf.gz.csi"
    conda: "envs/bcftools.yaml"
    shell: 'bcftools index -f {input}'

rule sample_make_prunelist:
    input: rules.extract_thin.output[0]
    output: "{dataout}/{sample}_pruned.snplist"
    shell: "cut -f2 {input} > {output}"

# Warn: subset called for sample that does not exist in header: "NA19176"... skipping
rule Reference_prune:
    input:
        vcf = "data/reference/{refname}_hg19_allChr_maxmiss0.05.vcf.gz",
        prune = "{dataout}/{sample}_pruned.snplist",
        founders = "data/reference/20130606_g1k.founders"
    output:
        vcf = temp("{dataout}/{sample}_{refname}pruned.vcf.gz"),
        tbi = temp("{dataout}/{sample}_{refname}pruned.vcf.gz.tbi")
    conda: "envs/bcftools.yaml"
    shell:
        r"""
        bcftools view -i 'ID=@{input.prune}' -S {input.founders} {input.vcf} --force-samples --threads 6 |\
        bcftools view -s ^NA20299,NA20314,NA20274,HG01880 -Oz -o {output.vcf} --force-samples --threads 6
        bcftools index -ft {output.vcf}
        """

# Merge ref and sample
rule Merge_RefenceSample:
    input:
        bcf_ref = "{dataout}/{sample}_{refname}pruned.vcf.gz",
        tbi_ref = "{dataout}/{sample}_{refname}pruned.vcf.gz.tbi",
        bcf_samp = "{dataout}/{sample}_thinned.vcf.gz",
        csi_samp = "{dataout}/{sample}_thinned.vcf.gz.csi",
    params:
        miss = GenoMiss,
    output:
        out = "{dataout}/{sample}_{refname}_merged.vcf"
    conda: "envs/bcftools.yaml"
    shell:
        r"""
        bcftools merge -m none --threads 2 \
          {input.bcf_ref} {input.bcf_samp} | \
          bcftools view  -i 'F_MISSING <= {params.miss}' -Ov -o {output.out} --threads 2
        """

# recode merged sample to plink
rule Plink_RefenceSample:
    input:
        vcf = "{dataout}/{sample}_{refname}_merged.vcf"
    output:
        multiext("{dataout}/{sample}_{refname}_merged", ".bed", ".bim", ".fam")
    params:
        out = "{dataout}/{sample}_{refname}_merged"
    conda: "envs/plink.yaml"
    shell: "plink --keep-allele-order --vcf {input.vcf} --const-fid --make-bed --out {params.out}"

rule fix_fam:
    input:
        oldfam = rules.sample_hapmap.output[2],
        newfam = "{dataout}/{sample}_{refname}_merged.fam",
        tgped = tgped,
        ref_pops = "data/reference/{refname}_pops.txt",
        ref_superpops = "data/reference/{refname}_superpops.txt"
    output:
        fixed = "{dataout}/{sample}_{refname}_merged_fixed.fam",
        pops = "{dataout}/{sample}_{refname}_merged.pop"
    conda: "envs/r.yaml"
    script: "scripts/fix_fam.R"

# PCA analysis to identify population outliers
rule PcaPopulationOutliers:
    input:
        plink = multiext("{dataout}/{sample}_{refname}_merged", ".bim", ".bed", ".fam"),
        fam = rules.fix_fam.output.fixed,
        ref = "data/reference/{refname}_pops.txt",
        clust = "data/reference/{refname}_pops_unique.txt"
    output:
        multiext("{dataout}/{sample}_{refname}_merged", '.eigenval', '.eigenvec')
    params:
        indat_plink = "{dataout}/{sample}_{refname}_merged",
        out = "{dataout}/{sample}_{refname}_merged"
    conda: "envs/plink.yaml"
    shell:
        """
        plink --keep-allele-order --bfile {params.indat_plink} --fam {input.fam} \
          --pca 10 --within {input.ref} --pca-clusters {input.clust} --out {params.out}
        """

rule cluster_pops:
    input:
        eigenvec = rules.PcaPopulationOutliers.output[1],
        ref_pops = "data/reference/{refname}_pops.txt",
        ref_superpops = "data/reference/{refname}_superpops.txt"
    params:
        Rlib = "/hpc/users/harern01/miniconda3/envs/py38/lib/R/library"
    output:
        pcs_pops = "{dataout}/{sample}_{refname}_pcs_pops.tsv"
    conda: 'envs/r.yaml'
    script: 'scripts/make_data.R'

rule plot_pca_tern:
    input:
        pcs = rules.cluster_pops.output.pcs_pops,
        ref_superpops = "data/reference/{refname}_superpops.txt"
    output: "{dataout}/plots/{sample}_{refname}_pca_tern.png"
    conda: 'envs/ggtern.yaml'
    script:'scripts/pca_tern_plot.R'

# Perform admixture
rule admixture:
    input:
        plink = multiext("{dataout}/{sample}_{refname}_merged", ".bim", ".bed", ".fam", ".pop"),
    output: multiext("{dataout}/{sample}_{refname}_merged.5", ".Q", ".P")
    params:
        stem = "{dataout}/{sample}_{refname}_merged",
        K = 5
    conda: 'envs/admixture.yaml'
    shell: #"admixture {params.stem}.bed {params.K} --supervised -j32"
        r"""
        admixture {params.stem}.bed {params.K} --supervised -j32;
        mv {wildcards.sample}_{wildcards.refname}_merged.5.Q {wildcards.dataout};
        mv {wildcards.sample}_{wildcards.refname}_merged.5.P {wildcards.dataout}
        """

# Combine admixture output and PCA ancestry file
rule combine:
    input:
        Qraw = rules.admixture.output[0],
        pops = rules.cluster_pops.output.pcs_pops
    output:
        Qheader = "{dataout}/{sample}_{refname}_merged.5.Qheader",
        outfile = "{dataout}/{sample}_{refname}_merged_admixture_pca"
    shell:
      r"""
      echo -e "K1\tK2\tK3\tK4\tK5" | cat - {input.Qraw} > {output.Qheader}
      paste {input.pops} {output.Qheader} > {output.outfile}
      """
# Assign ancestry following Helix paper
rule assign:
    input: rules.combine.output.outfile
    output:"{dataout}/{sample}_{refname}_merged_assigned_ancestry.tsv"
    conda: 'envs/r.yaml'
    script:'scripts/ancestry_assign.R'

# Make an admixture plot
rule plot:
    input:
        Qdat1 = rules.combine.output.outfile,
        Qdat2 = rules.assign.output
    output:
        p1 = "{dataout}/plots/{sample}_{refname}_admixture.png",
        p2 = "{dataout}/plots/{sample}_{refname}_admixture_assigned.png"
    conda: 'envs/r.yaml'
    script: 'scripts/admixtureplot.R'
